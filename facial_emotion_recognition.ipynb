{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Project Title:**  ***\" Facial Emotion Recognition\"***\n",
        "##### **Dataset:** *\"FER 2013 Dataset\"*\n",
        "##### **Step 01:** Loading Important Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Importing the required libraries.\n",
        "#To download the FER 2013 dataset.\n",
        "import kagglehub\n",
        "#For data preprocessing and augmentation.\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#For transfer learning with a pre-trained CNN model.\n",
        "from tensorflow.keras.applications import VGG16\n",
        "#For building the custom classification model.\n",
        "from tensorflow.keras.models import Model\n",
        "#For constructing the classifier.\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "#For training the model.\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#For alternative transfer learning with a pre-trained CNN model.\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "#For evaluating the model's performance.\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "#For numerical computations.\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Step 02:** Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pdF6fhWWlks",
        "outputId": "e8674591-5139-457a-ed7e-8df702ac8743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/msambare/fer2013?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 60.3M/60.3M [00:00<00:00, 90.6MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/msambare/fer2013/versions/1\n"
          ]
        }
      ],
      "source": [
        "#Downloading the latest version of the FER 2013 dataset from Kaggle using KaggleHub.\n",
        "path = kagglehub.dataset_download(\"msambare/fer2013\")\n",
        "#Printing the path where the dataset files have been saved after downloading and extracting.\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av4aeJLChh0f"
      },
      "source": [
        "##### **Step 03:** Data Preprocessing(Resizing, Normalizing, Augmenting Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ0a2i3JhixX",
        "outputId": "8011dc8b-2619-4abe-9f81-b20c0c70e516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 22968 images belonging to 7 classes.\n",
            "Found 5741 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "#Defining the paths to the training and testing directories of the FER 2013 dataset.\n",
        "train_dir = \"/root/.cache/kagglehub/datasets/msambare/fer2013/versions/1/train\"\n",
        "test_dir = \"/root/.cache/kagglehub/datasets/msambare/fer2013/versions/1/test\"\n",
        "#Creating an ImageDataGenerator for preprocessing and augmenting the dataset.\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,       #Normalize pixel values to the range [0, 1].\n",
        "    rotation_range=20,         #Randomly rotate images by up to 20 degrees for augmentation.\n",
        "    width_shift_range=0.2,     #Randomly shift images horizontally by up to 20% of the width.\n",
        "    height_shift_range=0.2,    #Randomly shift images vertically by up to 20% of the height.\n",
        "    horizontal_flip=True,      #Randomly flip images horizontally.\n",
        "    validation_split=0.2       #Reserve 20% of the training data for validation.\n",
        ")\n",
        "#Loading the training data, applying augmentation.\n",
        "train_data = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(48, 48),      #Resize all images to 48x48 pixels.\n",
        "    color_mode=\"rgb\",          #Convert grayscale images to RGB format (3 channels).\n",
        "    class_mode=\"categorical\",  #Use one-hot encoding for class labels.\n",
        "    batch_size=32,             #Process images in batches of 32.\n",
        "    subset=\"training\"          #Load the training subset.\n",
        ")\n",
        "#Loading the validation data, applying the same preprocessing as training data.\n",
        "val_data = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(48, 48),      #Resize all images to 48x48 pixels.\n",
        "    color_mode=\"rgb\",          #Convert grayscale images to RGB format (3 channels).\n",
        "    class_mode=\"categorical\",  #Use one-hot encoding for class labels.\n",
        "    batch_size=32,             #Process images in batches of 32.\n",
        "    subset=\"validation\"        #Load the validation subset.\n",
        ")\n",
        "#Creating a separate ImageDataGenerator for the test data (no augmentation, only normalization).\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)  #Normalize pixel values to [0, 1].\n",
        "#Loading the test data.\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(48, 48),      #Resize all images to 48x48 pixels.\n",
        "    color_mode=\"rgb\",          #Convert grayscale images to RGB format (3 channels).\n",
        "    class_mode=\"categorical\",  #Use one-hot encoding for class labels.\n",
        "    batch_size=32              #Process images in batches of 32.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juD0jFcfhrZr"
      },
      "source": [
        "##### **Step 04:** Transfer Learning with a Pre-Trained CNN Model (VGG16/ResNet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiIGJptrhsV8",
        "outputId": "e48107cf-5687-4c1a-800f-2a29750569c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m838s\u001b[0m 1s/step - accuracy: 0.2093 - loss: 1.9684 - val_accuracy: 0.3017 - val_loss: 1.7342\n",
            "Epoch 2/10\n",
            "\u001b[1m  1/717\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:15\u001b[0m 775ms/step - accuracy: 0.3438 - loss: 1.6800"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - accuracy: 0.3438 - loss: 1.6800 - val_accuracy: 0.1538 - val_loss: 1.9002\n",
            "Epoch 3/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m828s\u001b[0m 1s/step - accuracy: 0.2850 - loss: 1.7547 - val_accuracy: 0.3205 - val_loss: 1.7029\n",
            "Epoch 4/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 471us/step - accuracy: 0.1875 - loss: 1.8783 - val_accuracy: 0.3077 - val_loss: 1.6650\n",
            "Epoch 5/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m831s\u001b[0m 1s/step - accuracy: 0.3148 - loss: 1.7155 - val_accuracy: 0.3303 - val_loss: 1.6887\n",
            "Epoch 6/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step - accuracy: 0.2188 - loss: 1.8342 - val_accuracy: 0.0000e+00 - val_loss: 2.0276\n",
            "Epoch 7/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m826s\u001b[0m 1s/step - accuracy: 0.3126 - loss: 1.7051 - val_accuracy: 0.3319 - val_loss: 1.6735\n",
            "Epoch 8/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470us/step - accuracy: 0.4688 - loss: 1.4732 - val_accuracy: 0.2308 - val_loss: 2.0098\n",
            "Epoch 9/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m826s\u001b[0m 1s/step - accuracy: 0.3260 - loss: 1.6872 - val_accuracy: 0.3293 - val_loss: 1.6707\n",
            "Epoch 10/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 472us/step - accuracy: 0.3750 - loss: 1.7063 - val_accuracy: 0.6154 - val_loss: 1.3633\n"
          ]
        }
      ],
      "source": [
        "#Loading the VGG16 model without the top layers.\n",
        "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(48, 48, 3))\n",
        "#Freezing all the layers in the base model to retain pre-trained features.\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False  #Prevent updates to the weights during training.\n",
        "#Adding custom layers for emotion classification.\n",
        "x = base_model.output          #Start with the output of the base model.\n",
        "x = Flatten()(x)               #Flatten the feature maps into a 1D vector.\n",
        "x = Dense(256, activation=\"relu\")(x)  #Add a dense (fully connected) layer with 256 units and ReLU activation.\n",
        "x = Dropout(0.5)(x)            #Apply dropout to reduce overfitting.\n",
        "output = Dense(7, activation=\"softmax\")(x)  #Add the output layer with 7 units (one for each emotion class) and softmax activation.\n",
        "#Creating the final model by connecting the base model and custom layers.\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "#Compiling the model with Adam optimizer, categorical crossentropy loss and accuracy as the evaluation metric.\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),  #Use a small learning rate for stable training.\n",
        "    loss=\"categorical_crossentropy\",     #Suitable for multi-class classification.\n",
        "    metrics=[\"accuracy\"]                 #Monitor accuracy during training.\n",
        ")\n",
        "#Training the model on the training data and validate on the validation data.\n",
        "history = model.fit(\n",
        "    train_data,                          #Training data generator.\n",
        "    validation_data=val_data,            #Validation data generator.\n",
        "    epochs=10,                           #Number of epochs to train.\n",
        "    steps_per_epoch=train_data.samples // train_data.batch_size,  #Steps per epoch for training.\n",
        "    validation_steps=val_data.samples // val_data.batch_size      #Steps per epoch for validation.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0in6VJpnyA83",
        "outputId": "32e88f0d-fb88-43ec-aafd-b5936d00e519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 463ms/step - accuracy: 0.2202 - loss: 1.9098 - val_accuracy: 0.2505 - val_loss: 1.8093\n",
            "Epoch 2/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - accuracy: 0.3125 - loss: 1.9497 - val_accuracy: 0.2308 - val_loss: 1.7649\n",
            "Epoch 3/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 462ms/step - accuracy: 0.2342 - loss: 1.8247 - val_accuracy: 0.2533 - val_loss: 1.8037\n",
            "Epoch 4/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step - accuracy: 0.1562 - loss: 1.8957 - val_accuracy: 0.2308 - val_loss: 1.7916\n",
            "Epoch 5/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 461ms/step - accuracy: 0.2394 - loss: 1.8261 - val_accuracy: 0.2512 - val_loss: 1.8011\n",
            "Epoch 6/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420us/step - accuracy: 0.2500 - loss: 1.7495 - val_accuracy: 0.3846 - val_loss: 1.7962\n",
            "Epoch 7/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 462ms/step - accuracy: 0.2446 - loss: 1.8186 - val_accuracy: 0.2519 - val_loss: 1.8006\n",
            "Epoch 8/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - accuracy: 0.1562 - loss: 1.8677 - val_accuracy: 0.0769 - val_loss: 1.8856\n",
            "Epoch 9/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 459ms/step - accuracy: 0.2401 - loss: 1.8149 - val_accuracy: 0.2519 - val_loss: 1.8114\n",
            "Epoch 10/10\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409us/step - accuracy: 0.2188 - loss: 1.8191 - val_accuracy: 0.0000e+00 - val_loss: 1.8598\n"
          ]
        }
      ],
      "source": [
        "#Loading the ResNet50 model without the top layers.\n",
        "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(48, 48, 3))\n",
        "#Freezing all the layers in the base model to retain pre-trained features.\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False  #Prevent updates to the weights of the pre-trained layers during training.\n",
        "#Adding custom layers for emotion classification.\n",
        "x = base_model.output          #Start with the output of the base model.\n",
        "x = Flatten()(x)               #Flatten the feature maps into a 1D vector.\n",
        "x = Dense(256, activation=\"relu\")(x)  #Add a dense (fully connected) layer with 256 units and ReLU activation.\n",
        "x = Dropout(0.5)(x)            #Apply dropout with a 50% rate to reduce overfitting.\n",
        "output = Dense(7, activation=\"softmax\")(x)  #Add the output layer with 7 units (one for each emotion class) and softmax activation.\n",
        "#Creating the final model by combining the base model and custom layers.\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "#Compiling the model with Adam optimizer, categorical crossentropy loss and accuracy as the evaluation metric.\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),  #Use a small learning rate for stable training.\n",
        "    loss=\"categorical_crossentropy\",     #Suitable for multi-class classification.\n",
        "    metrics=[\"accuracy\"]                 #Monitor accuracy during training.\n",
        ")\n",
        "#Training the model on the training data and validate on the validation data.\n",
        "history = model.fit(\n",
        "    train_data,                          #Training data generator.\n",
        "    validation_data=val_data,            #Validation data generator.\n",
        "    epochs=10,                           #Number of epochs to train.\n",
        "    steps_per_epoch=train_data.samples // train_data.batch_size,  #Steps per epoch for training.\n",
        "    validation_steps=val_data.samples // val_data.batch_size      #Steps per epoch for validation.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFRbvQVA3_8D"
      },
      "source": [
        "##### **Step 05:** Fine-Tuning the Model and Evaluating Its Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0CKn6oo4Bab",
        "outputId": "f6d27a0c-8926-4fa8-a478-22a638a271c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 486ms/step - accuracy: 0.2347 - loss: 1.8242 - val_accuracy: 0.2544 - val_loss: 1.7957\n",
            "Epoch 2/5\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454us/step - accuracy: 0.2812 - loss: 1.6948 - val_accuracy: 0.2308 - val_loss: 1.8287\n",
            "Epoch 3/5\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 487ms/step - accuracy: 0.2521 - loss: 1.8047 - val_accuracy: 0.2556 - val_loss: 1.7849\n",
            "Epoch 4/5\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249us/step - accuracy: 0.2188 - loss: 1.8573 - val_accuracy: 0.1538 - val_loss: 1.9231\n",
            "Epoch 5/5\n",
            "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 486ms/step - accuracy: 0.2490 - loss: 1.8043 - val_accuracy: 0.2558 - val_loss: 1.7872\n"
          ]
        }
      ],
      "source": [
        "#Unfreezing the last few layers of the base model for fine-tuning.\n",
        "for layer in base_model.layers[-4:]:  #Unfreeze the last 4 layers.\n",
        "    layer.trainable = True\n",
        "#Recompiling the model with a smaller learning rate.\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),  #Smaller learning rate for fine-tuning.\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "#Fine-tuning the model.\n",
        "history_fine_tune = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=5,  #Additional epochs for fine-tuning.\n",
        "    steps_per_epoch=train_data.samples // train_data.batch_size,\n",
        "    validation_steps=val_data.samples // val_data.batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4p6zrSbSemz",
        "outputId": "bd45d061-6dd4-46d2-c4a3-a185d57ce2a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 348ms/step - accuracy: 0.2467 - loss: 1.7943\n",
            "Validation Loss after Fine-Tuning: 1.7866168022155762\n",
            "Validation Accuracy after Fine-Tuning: 0.25831738114356995\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 326ms/step - accuracy: 0.2671 - loss: 1.7778\n",
            "Test Loss: 1.777564287185669\n",
            "Test Accuracy: 0.26469770073890686\n"
          ]
        }
      ],
      "source": [
        "#Evaluating the model on validation data.\n",
        "val_loss, val_accuracy = model.evaluate(val_data)\n",
        "print(\"Validation Loss after Fine-Tuning:\", val_loss)\n",
        "print(\"Validation Accuracy after Fine-Tuning:\", val_accuracy)\n",
        "#Evaluating the model on test data.\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2pGM1BDUotd"
      },
      "source": [
        "##### **Step 06:** Reporting metrics "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwb3cD2FUr1a",
        "outputId": "40e42ebf-ceac-43a0-900a-3f9f6160a6d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 332ms/step\n",
            "Test Accuracy: 0.2329\n",
            "F1-Score for angry: 0.0261\n",
            "F1-Score for disgust: 0.0000\n",
            "F1-Score for fear: 0.0149\n",
            "F1-Score for happy: 0.3864\n",
            "F1-Score for neutral: 0.0492\n",
            "F1-Score for sad: 0.0109\n",
            "F1-Score for surprise: 0.0834\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.12      0.01      0.03       958\n",
            "     disgust       0.00      0.00      0.00       111\n",
            "        fear       0.15      0.01      0.01      1024\n",
            "       happy       0.25      0.87      0.39      1774\n",
            "     neutral       0.16      0.03      0.05      1233\n",
            "         sad       0.20      0.01      0.01      1247\n",
            "    surprise       0.11      0.07      0.08       831\n",
            "\n",
            "    accuracy                           0.23      7178\n",
            "   macro avg       0.14      0.14      0.08      7178\n",
            "weighted avg       0.17      0.23      0.12      7178\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "#Getting ground truth labels and predictions.\n",
        "test_labels = test_data.classes  #True labels.\n",
        "class_names = list(test_data.class_indices.keys())  #Emotion class names.\n",
        "#Predicting probabilities.\n",
        "predictions = model.predict(test_data, steps=test_data.samples // test_data.batch_size + 1)\n",
        "#Converting predicted probabilities to class labels.\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "#Reporting accuracy.\n",
        "accuracy = accuracy_score(test_labels, predicted_classes)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "#Reporting F1-score for each class.\n",
        "f1_scores = f1_score(test_labels, predicted_classes, average=None)\n",
        "for i, score in enumerate(f1_scores):\n",
        "    print(f\"F1-Score for {class_names[i]}: {score:.4f}\")\n",
        "#Generating a detailed classification report.\n",
        "report = classification_report(test_labels, predicted_classes, target_names=class_names)\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Akw4CmIWyMO"
      },
      "source": [
        "### **Conclusion**\n",
        "\n",
        "##### This project utilized the **FER 2013 dataset** and transfer learning with **VGG16** to classify emotions. The model achieved a **23.29% test accuracy**, with \"happy\" being the best-recognized emotion (**F1-score: 0.39**), while other emotions, such as \"disgust\" and \"sad,\" had near-zero F1-scores.\n",
        "\n",
        "#### **Key Insights**\n",
        "1. **Dataset Imbalance**  \n",
        "   The highly imbalanced dataset significantly impacted model performance, especially for underrepresented emotions like \"disgust.\"\n",
        "2. **Subtle Features**  \n",
        "   General pre-trained models like VGG16 struggled to capture the nuanced facial expressions required for accurate emotion recognition.\n",
        "3. **Result Portrayal**  \n",
        "   The low accuracy and poor F1-scores highlight that the dataset and current approach are insufficient for reliable emotion recognition.\n",
        "The results underscore the need for more balanced datasets and specialized models to achieve robust facial emotion recognition. While this project lays a foundation, further enhancements are necessary to improve accuracy and generalization. \n",
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
